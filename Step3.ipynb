{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from lib.modules import (\n",
    "    evaluate_loop, \n",
    "    read_and_window_session,\n",
    "    read_session,\n",
    "    train_loop,\n",
    "    optimization_loop,\n",
    "    predict_and_plot_pretty_session\n",
    ")\n",
    "from lib.utils import (\n",
    "    plot_and_save_cm,\n",
    "    summary\n",
    ")\n",
    "from lib.models import  MLP, MLP2hl\n",
    "from tqdm import tqdm\n",
    "import plotly.express as px\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dir = Path(\"/home/musa/datasets/nursingv1\")\n",
    "label_dir = Path(\"/home/musa/datasets/eating_labels\")\n",
    "WINSIZE = 101\n",
    "DEVICE = 'cuda:1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sessions = [25, 67, 42]\n",
    "test_sessions = [58, 62]\n",
    "\n",
    "Xs = []\n",
    "ys = []\n",
    "\n",
    "for session_idx in train_sessions:\n",
    "    X,y = read_and_window_session(session_idx, WINSIZE, raw_dir, label_dir)\n",
    "\n",
    "    Xs.append(X)\n",
    "    ys.append(y)\n",
    "\n",
    "Xtr = torch.cat(Xs)\n",
    "ytr = torch.cat(ys)\n",
    "\n",
    "Xs = []\n",
    "ys = []\n",
    "\n",
    "for session_idx in test_sessions:\n",
    "    X,y = read_and_window_session(session_idx, WINSIZE, raw_dir, label_dir)\n",
    "\n",
    "    Xs.append(X)\n",
    "    ys.append(y)\n",
    "\n",
    "Xte = torch.cat(Xs)\n",
    "yte = torch.cat(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP2hl([20,20], WINSIZE).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: Train Loss: 0.22026: Dev Loss: 0.85166: 100%|██████████| 50/50 [08:51<00:00, 10.63s/it]\n"
     ]
    }
   ],
   "source": [
    "trainloader = DataLoader(TensorDataset(Xtr, ytr), batch_size=64, shuffle=True)\n",
    "testloader = DataLoader(TensorDataset(Xte,yte), batch_size=64)\n",
    "\n",
    "optimization_loop(model, trainloader, testloader, criterion, optimizer, 50, DEVICE, Path('dev/mlp2hl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for MLP2hl:\n\tMissing key(s) in state_dict: \"h1.weight\", \"h1.bias\", \"h2.weight\", \"h2.bias\", \"out.weight\", \"out.bias\". \n\tUnexpected key(s) in state_dict: \"resnet_conv.shortcut1.0.weight\", \"resnet_conv.shortcut1.0.bias\", \"resnet_conv.shortcut1.1.weight\", \"resnet_conv.shortcut1.1.bias\", \"resnet_conv.shortcut1.1.running_mean\", \"resnet_conv.shortcut1.1.running_var\", \"resnet_conv.shortcut1.1.num_batches_tracked\", \"resnet_conv.res1.0.0.weight\", \"resnet_conv.res1.0.0.bias\", \"resnet_conv.res1.0.1.weight\", \"resnet_conv.res1.0.1.bias\", \"resnet_conv.res1.0.1.running_mean\", \"resnet_conv.res1.0.1.running_var\", \"resnet_conv.res1.0.1.num_batches_tracked\", \"resnet_conv.res1.1.0.weight\", \"resnet_conv.res1.1.0.bias\", \"resnet_conv.res1.1.1.weight\", \"resnet_conv.res1.1.1.bias\", \"resnet_conv.res1.1.1.running_mean\", \"resnet_conv.res1.1.1.running_var\", \"resnet_conv.res1.1.1.num_batches_tracked\", \"resnet_conv.res1.2.0.weight\", \"resnet_conv.res1.2.0.bias\", \"resnet_conv.res1.2.1.weight\", \"resnet_conv.res1.2.1.bias\", \"resnet_conv.res1.2.1.running_mean\", \"resnet_conv.res1.2.1.running_var\", \"resnet_conv.res1.2.1.num_batches_tracked\", \"resnet_conv.shortcut3.0.weight\", \"resnet_conv.shortcut3.0.bias\", \"resnet_conv.shortcut3.1.weight\", \"resnet_conv.shortcut3.1.bias\", \"resnet_conv.shortcut3.1.running_mean\", \"resnet_conv.shortcut3.1.running_var\", \"resnet_conv.shortcut3.1.num_batches_tracked\", \"resnet_conv.res3.0.0.weight\", \"resnet_conv.res3.0.0.bias\", \"resnet_conv.res3.0.1.weight\", \"resnet_conv.res3.0.1.bias\", \"resnet_conv.res3.0.1.running_mean\", \"resnet_conv.res3.0.1.running_var\", \"resnet_conv.res3.0.1.num_batches_tracked\", \"resnet_conv.res3.1.0.weight\", \"resnet_conv.res3.1.0.bias\", \"resnet_conv.res3.1.1.weight\", \"resnet_conv.res3.1.1.bias\", \"resnet_conv.res3.1.1.running_mean\", \"resnet_conv.res3.1.1.running_var\", \"resnet_conv.res3.1.1.num_batches_tracked\", \"resnet_conv.res3.2.0.weight\", \"resnet_conv.res3.2.0.bias\", \"resnet_conv.res3.2.1.weight\", \"resnet_conv.res3.2.1.bias\", \"resnet_conv.res3.2.1.running_mean\", \"resnet_conv.res3.2.1.running_var\", \"resnet_conv.res3.2.1.num_batches_tracked\", \"output.weight\", \"output.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# model.load_state_dict(torch.load(Path('dev/mlp2hl/best_model.pt')))\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model\u001b[39m.\u001b[39;49mload_state_dict(torch\u001b[39m.\u001b[39;49mload(Path(\u001b[39m'\u001b[39;49m\u001b[39mdev/resnet_model.pt\u001b[39;49m\u001b[39m'\u001b[39;49m)))\n",
      "File \u001b[0;32m~/eating/eating-detection/env/lib/python3.10/site-packages/torch/nn/modules/module.py:2152\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2147\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[1;32m   2148\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2149\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mk\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2151\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 2152\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   2153\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2154\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for MLP2hl:\n\tMissing key(s) in state_dict: \"h1.weight\", \"h1.bias\", \"h2.weight\", \"h2.bias\", \"out.weight\", \"out.bias\". \n\tUnexpected key(s) in state_dict: \"resnet_conv.shortcut1.0.weight\", \"resnet_conv.shortcut1.0.bias\", \"resnet_conv.shortcut1.1.weight\", \"resnet_conv.shortcut1.1.bias\", \"resnet_conv.shortcut1.1.running_mean\", \"resnet_conv.shortcut1.1.running_var\", \"resnet_conv.shortcut1.1.num_batches_tracked\", \"resnet_conv.res1.0.0.weight\", \"resnet_conv.res1.0.0.bias\", \"resnet_conv.res1.0.1.weight\", \"resnet_conv.res1.0.1.bias\", \"resnet_conv.res1.0.1.running_mean\", \"resnet_conv.res1.0.1.running_var\", \"resnet_conv.res1.0.1.num_batches_tracked\", \"resnet_conv.res1.1.0.weight\", \"resnet_conv.res1.1.0.bias\", \"resnet_conv.res1.1.1.weight\", \"resnet_conv.res1.1.1.bias\", \"resnet_conv.res1.1.1.running_mean\", \"resnet_conv.res1.1.1.running_var\", \"resnet_conv.res1.1.1.num_batches_tracked\", \"resnet_conv.res1.2.0.weight\", \"resnet_conv.res1.2.0.bias\", \"resnet_conv.res1.2.1.weight\", \"resnet_conv.res1.2.1.bias\", \"resnet_conv.res1.2.1.running_mean\", \"resnet_conv.res1.2.1.running_var\", \"resnet_conv.res1.2.1.num_batches_tracked\", \"resnet_conv.shortcut3.0.weight\", \"resnet_conv.shortcut3.0.bias\", \"resnet_conv.shortcut3.1.weight\", \"resnet_conv.shortcut3.1.bias\", \"resnet_conv.shortcut3.1.running_mean\", \"resnet_conv.shortcut3.1.running_var\", \"resnet_conv.shortcut3.1.num_batches_tracked\", \"resnet_conv.res3.0.0.weight\", \"resnet_conv.res3.0.0.bias\", \"resnet_conv.res3.0.1.weight\", \"resnet_conv.res3.0.1.bias\", \"resnet_conv.res3.0.1.running_mean\", \"resnet_conv.res3.0.1.running_var\", \"resnet_conv.res3.0.1.num_batches_tracked\", \"resnet_conv.res3.1.0.weight\", \"resnet_conv.res3.1.0.bias\", \"resnet_conv.res3.1.1.weight\", \"resnet_conv.res3.1.1.bias\", \"resnet_conv.res3.1.1.running_mean\", \"resnet_conv.res3.1.1.running_var\", \"resnet_conv.res3.1.1.num_batches_tracked\", \"resnet_conv.res3.2.0.weight\", \"resnet_conv.res3.2.0.bias\", \"resnet_conv.res3.2.1.weight\", \"resnet_conv.res3.2.1.bias\", \"resnet_conv.res3.2.1.running_mean\", \"resnet_conv.res3.2.1.running_var\", \"resnet_conv.res3.2.1.num_batches_tracked\", \"output.weight\", \"output.bias\". "
     ]
    }
   ],
   "source": [
    "# model.load_state_dict(torch.load(Path('dev/mlp2hl/best_model.pt')))\n",
    "model.load_state_dict(torch.load(Path('dev/mlp2hl/best_model.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys,metrics = evaluate_loop(model, criterion, trainloader, DEVICE)\n",
    "plot_and_save_cm(ys['true'], ys['pred'])\n",
    "summary(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys,metrics = evaluate_loop(model, criterion, testloader, DEVICE)\n",
    "plot_and_save_cm(ys['true'], ys['pred'])\n",
    "summary(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_session = test_sessions[0]\n",
    "\n",
    "predict_and_plot_pretty_session(\n",
    "    session_idx=test_session,\n",
    "    dim_factor=5,\n",
    "    datapath=raw_dir,\n",
    "    labelpath=label_dir,\n",
    "    winsize=WINSIZE,\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    batch_size=64,\n",
    "    device=DEVICE\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "07a7e9baaa56ad5291b67d7a98d93b7d3a1f6016f598f84e49730f5552732cf1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
