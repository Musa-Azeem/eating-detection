{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "at::Tensor conv_transpose1d(\n",
    "    const Tensor& input_, const Tensor& weight, const c10::optional<Tensor>& bias_opt,\n",
    "    IntArrayRef stride, IntArrayRef padding, IntArrayRef output_padding, int64_t groups, IntArrayRef dilation) {\n",
    "  // See [Note: hacky wrapper removal for optional tensor]\n",
    "  c10::MaybeOwned<Tensor> bias_maybe_owned = at::borrow_from_optional_tensor(bias_opt);\n",
    "  const Tensor& bias = *bias_maybe_owned;\n",
    "\n",
    "  Tensor input;\n",
    "  bool is_batched;\n",
    "  std::tie(input, is_batched) = batchify(input_, /*num_spatial_dims=*/ 1, \"conv_transpose1d\");\n",
    "  Tensor output;\n",
    "  if (at::isComplexType(input_.scalar_type())) {\n",
    "    output = complex_convolution(\n",
    "      input, weight, bias, stride, padding, dilation, true, output_padding, groups);\n",
    "  } else {\n",
    "    output = at::convolution(\n",
    "      input, weight, bias, stride, padding, dilation, true, output_padding, groups);\n",
    "  }\n",
    "  return is_batched ? output : output.squeeze(0);\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.randn(1, 1, 5)\n",
    "\n",
    "c1 = nn.Conv1d(1, 2, 3, padding=1, bias=False)\n",
    "ct1 = nn.ConvTranspose1d(1, 2, 3, padding=1, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1.weight.data = ct1.weight.data.transpose(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1(test).equal(ct1(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct1(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = pd.read_csv('/home/musa/datasets/eating_raw/11-01_20_54_52/acceleration-11-01_20_54_52.csv', skiprows=1)\n",
    "X = torch.Tensor(acc[['x','y','z']].values)\n",
    "# chunk_len = 5 * 60 * 60 * 100 # = 1,800,000 samples ie. 5 hours of recording\n",
    "# X = X[:len(X) - len(X) % chunk_len]\n",
    "# X = X.view(-1, chunk_len, 3)\n",
    "\n",
    "# train test split chunks to get Xtr and Xte\n",
    "# Xtr = pad_for_windowing(X, 101) # no test set for now\n",
    "# Xtr = Xtr.flatten(end_dim=1)\n",
    "Xtr = AccRawDataset(X[:100000], 101)\n",
    "trainloader = torch.utils.data.DataLoader(Xtr, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResAutoEncoder(101, 3).to('cuda:0')\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "\n",
    "    loss_all = 0\n",
    "    for X in trainloader:\n",
    "        X = X.to('cuda:0')\n",
    "        X_pred = model(X)\n",
    "        loss = criterion(X_pred, X)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_all += loss.item()\n",
    "\n",
    "    print(loss / len(trainloader))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "i = 450\n",
    "plt.plot(model(Xtr[i].to('cuda:0').unsqueeze(0))[0][202:302].detach().cpu(), label='pred')\n",
    "plt.plot(Xtr[i][202:303], label='true')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
